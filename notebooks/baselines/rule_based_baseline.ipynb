{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3729c537-b22e-4806-a38a-7291c97dc73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Rule-Based Baseline\n",
    "\n",
    "Simple rule: The squad with the **lowest `dist_from_bluezone`** (closest to safezone) is predicted as the winner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd1c7614-3c03-40f5-9775-c30899d70272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, '/Users/seunghan96/pgc_wwcd_prediction')\n",
    "\n",
    "# Constants\n",
    "NUM_PHASES = 10\n",
    "SAMPLES_PER_PHASE = 5\n",
    "TARGET_SCALE = 2000.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3091d13f-cca9-4e20-a366-d335542e94d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c9f3dc-4f72-48f0-a32e-d188d7d2f4c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data paths (same as other experiments)\n",
    "FOLDER_PATH = \"/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/pgc_features/inference_v2\"\n",
    "SPLIT_CSV_PATH = \"/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/pgc_features/inference_v2/split_files.csv\"\n",
    "\n",
    "# Load split info\n",
    "split_df = pd.read_csv(SPLIT_CSV_PATH)\n",
    "test_files = split_df[split_df['split'] == 'test']['filename'].tolist()\n",
    "print(f\"Test files: {len(test_files)}\")\n",
    "\n",
    "# Load test data\n",
    "test_dfs = []\n",
    "for f in tqdm(test_files, desc=\"Loading test data\"):\n",
    "    df = pd.read_csv(os.path.join(FOLDER_PATH, f))\n",
    "    test_dfs.append(df)\n",
    "\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)\n",
    "print(f\"Test data: {len(test_df):,} rows\")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84d4fd84-ecc0-4541-8e16-7508702a47a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# ============================================\n",
    "# Parsing Functions\n",
    "# ============================================\n",
    "\n",
    "def parse_positions(positions_str):\n",
    "    \"\"\"Parse positions string to list of [x, y, z] coordinates\"\"\"\n",
    "    \n",
    "    if isinstance(positions_str, str):\n",
    "        positions = ast.literal_eval(positions_str)\n",
    "    else:\n",
    "        positions = positions_str\n",
    "    \n",
    "    if not isinstance(positions, list):\n",
    "        return []\n",
    "    \n",
    "    # Ensure each position has [x, y, z]\n",
    "    parsed = []\n",
    "    for pos in positions:\n",
    "        if isinstance(pos, (list, tuple)) and len(pos) >= 3:\n",
    "            parsed.append([float(pos[0]), float(pos[1]), float(pos[2])])\n",
    "    return parsed\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_bluezone(bluezone_str):\n",
    "    \"\"\"Parse bluezone_info to extract center coordinates [x, y, radius]\"\"\"\n",
    "    if 'np.float64' in str(bluezone_str):\n",
    "        pattern = r'np\\.float64\\(([-\\d.]+)\\)'\n",
    "        matches = re.findall(pattern, str(bluezone_str))\n",
    "        if len(matches) >= 3:\n",
    "            return {\n",
    "                'x': float(matches[0]),\n",
    "                'y': float(matches[1]),\n",
    "                'radius': float(matches[2])\n",
    "            }\n",
    "    \n",
    "    # Original parsing logic for other formats\n",
    "    if isinstance(bluezone_str, str):\n",
    "        bluezone = ast.literal_eval(bluezone_str)\n",
    "    else:\n",
    "        bluezone = bluezone_str\n",
    "    \n",
    "    # Handle various formats: [[x, y, radius]] or [x, y, radius]\n",
    "    coords = None\n",
    "    if isinstance(bluezone, (list, tuple)) and len(bluezone) > 0:\n",
    "        first_elem = bluezone[0]\n",
    "        if isinstance(first_elem, (list, tuple)) and len(first_elem) >= 3:\n",
    "            coords = first_elem\n",
    "        elif hasattr(first_elem, '__float__') or isinstance(first_elem, (int, float)):\n",
    "            if len(bluezone) >= 3:\n",
    "                coords = bluezone\n",
    "    \n",
    "    if coords is not None and len(coords) >= 3:\n",
    "        return {\n",
    "            'x': float(coords[0]),\n",
    "            'y': float(coords[1]),\n",
    "            'radius': float(coords[2])\n",
    "        }\n",
    "\n",
    "\n",
    "def calculate_distance(p1, p2):\n",
    "    \"\"\"Calculate Euclidean distance between two 2D points\"\"\"\n",
    "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "\n",
    "def get_squad_center(positions):\n",
    "    \"\"\"Calculate center position (x, y) of a squad from positions\"\"\"\n",
    "    x_coords = [p[0] for p in positions if len(p) >= 2]\n",
    "    y_coords = [p[1] for p in positions if len(p) >= 2]\n",
    "    if x_coords and y_coords:\n",
    "        return [np.mean(x_coords), np.mean(y_coords)]\n",
    "\n",
    "\n",
    "def compute_dist_from_zone_v2(row, zone_col='bluezone_info'):\n",
    "    \"\"\"\n",
    "    Compute distance from squad center to zone center, normalized by zone radius.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        zone_col: Column name for zone info ('bluezone_info' or 'whitezone_info')\n",
    "    \n",
    "    Returns:\n",
    "        Distance from squad center to zone center / zone radius\n",
    "        Returns NaN if parsing fails\n",
    "    \"\"\"\n",
    "    # Parse positions and zone info\n",
    "    positions = parse_positions(row['positions'])\n",
    "    zone_info = parse_bluezone(row[zone_col])\n",
    "    \n",
    "    # Get squad center\n",
    "    squad_center = get_squad_center(positions)\n",
    "    \n",
    "    # Calculate distance to zone center\n",
    "    zone_center = [zone_info['x'], zone_info['y']]\n",
    "    distance = calculate_distance(squad_center, zone_center)\n",
    "    \n",
    "    if zone_info['radius'] > 0:\n",
    "        return distance / zone_info['radius']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "print(\"Parsing functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ab41126-aba5-46b0-9e12-70991616c210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Rule-Based Prediction\n",
    "\n",
    "**Rule**: Lower `dist_from_bluezone` = Higher chance of winning\n",
    "\n",
    "We use negative `dist_from_bluezone` as the \"prediction score\" so that argmax gives us the squad closest to the safezone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8288670-7894-413f-96ef-ba320a417478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Compute dist_from_bluezone_v2 and dist_from_whitezone_v2\n",
    "# ============================================\n",
    "print(\"Computing dist_from_bluezone_v2...\")\n",
    "test_df['dist_from_bluezone_v2'] = test_df.apply(\n",
    "    lambda row: compute_dist_from_zone_v2(row, zone_col='bluezone_info'), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Computing dist_from_whitezone_v2...\")\n",
    "test_df['dist_from_whitezone_v2'] = test_df.apply(\n",
    "    lambda row: compute_dist_from_zone_v2(row, zone_col='whitezone_info'), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(\"\\n--- dist_from_bluezone_v2 ---\")\n",
    "print(f\"  Valid values: {test_df['dist_from_bluezone_v2'].notna().sum():,} / {len(test_df):,}\")\n",
    "print(f\"  Min: {test_df['dist_from_bluezone_v2'].min():.4f}\")\n",
    "print(f\"  Max: {test_df['dist_from_bluezone_v2'].max():.4f}\")\n",
    "print(f\"  Mean: {test_df['dist_from_bluezone_v2'].mean():.4f}\")\n",
    "\n",
    "print(\"\\n--- dist_from_whitezone_v2 ---\")\n",
    "print(f\"  Valid values: {test_df['dist_from_whitezone_v2'].notna().sum():,} / {len(test_df):,}\")\n",
    "print(f\"  Min: {test_df['dist_from_whitezone_v2'].min():.4f}\")\n",
    "print(f\"  Max: {test_df['dist_from_whitezone_v2'].max():.4f}\")\n",
    "print(f\"  Mean: {test_df['dist_from_whitezone_v2'].mean():.4f}\")\n",
    "\n",
    "# Compare with original dist_from_bluezone\n",
    "print(\"\\n--- Correlation with original ---\")\n",
    "print(f\"  Corr(dist_from_bluezone, dist_from_bluezone_v2): {test_df['dist_from_bluezone'].corr(test_df['dist_from_bluezone_v2']):.4f}\")\n",
    "print(f\"  Corr(dist_from_whitezone, dist_from_whitezone_v2): {test_df['dist_from_whitezone'].corr(test_df['dist_from_whitezone_v2']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f72e850-bcaf-4ebc-8494-d3d144efd6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_df['dist_from_bluezone_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92a4b3a4-2ba1-408a-8fa8-da882782cddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rule-based prediction: lower dist_from_bluezone = higher score\n",
    "# Use negative so argmax gives the squad closest to safezone\n",
    "test_df['pred'] = -test_df['dist_from_bluezone']\n",
    "\n",
    "print(\"Prediction based on: -dist_from_bluezone\")\n",
    "print(f\"  Min pred: {test_df['pred'].min():.4f}\")\n",
    "print(f\"  Max pred: {test_df['pred'].max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a3ed321-fadf-40f4-8cca-3db1003c32d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Compute Phase-wise Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5530b78f-8f6a-4a1e-8662-79dfaa03668c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_ece(confidences, accuracies, n_bins=10):\n",
    "    \"\"\"Compute Expected Calibration Error.\"\"\"\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        bin_lower = bin_boundaries[i]\n",
    "        bin_upper = bin_boundaries[i + 1]\n",
    "\n",
    "        in_bin = (confidences > bin_lower) & (confidences <= bin_upper)\n",
    "        n_in_bin = np.sum(in_bin)\n",
    "\n",
    "        if n_in_bin > 0:\n",
    "            avg_confidence = np.mean(confidences[in_bin])\n",
    "            avg_accuracy = np.mean(accuracies[in_bin])\n",
    "            ece += n_in_bin * abs(avg_accuracy - avg_confidence)\n",
    "            total_samples += n_in_bin\n",
    "\n",
    "    if total_samples > 0:\n",
    "        ece /= total_samples\n",
    "\n",
    "    return ece\n",
    "\n",
    "\n",
    "def compute_metrics_by_phase(df, pred_col='pred', target_col='squad_death_time'):\n",
    "    \"\"\"\n",
    "    Compute phase-wise metrics (accuracy, log_loss, ece).\n",
    "    Groups by (match_id, time_point) and computes winner prediction metrics.\n",
    "    \"\"\"\n",
    "    # Group by match_id and sort by time_point\n",
    "    match_groups = df.groupby('match_id')\n",
    "\n",
    "    # Build phase mapping\n",
    "    phase_data = defaultdict(list)\n",
    "\n",
    "    for match_id, match_df in match_groups:\n",
    "        # Sort by time_point\n",
    "        time_points = sorted(match_df['time_point'].unique())\n",
    "\n",
    "        for tp_idx, time_point in enumerate(time_points):\n",
    "            phase = min(tp_idx // SAMPLES_PER_PHASE + 1, NUM_PHASES)\n",
    "\n",
    "            # Get all squads at this time_point\n",
    "            tp_df = match_df[match_df['time_point'] == time_point]\n",
    "\n",
    "            preds = tp_df[pred_col].values\n",
    "            targets = tp_df[target_col].values / TARGET_SCALE\n",
    "\n",
    "            phase_data[phase].append({\n",
    "                'preds': preds,\n",
    "                'targets': targets,\n",
    "            })\n",
    "\n",
    "    # Compute metrics per phase\n",
    "    results = {\n",
    "        'accuracy': {},\n",
    "        'log_loss': {},\n",
    "        'ece': {},\n",
    "    }\n",
    "\n",
    "    all_correct = 0\n",
    "    all_total = 0\n",
    "    all_log_losses = []\n",
    "    all_confidences = []\n",
    "    all_accuracies = []\n",
    "\n",
    "    for phase in range(1, NUM_PHASES + 1):\n",
    "        if phase not in phase_data:\n",
    "            for metric in results:\n",
    "                results[metric][f'Phase_{phase}'] = 0.0\n",
    "            continue\n",
    "\n",
    "        phase_correct = 0\n",
    "        phase_total = 0\n",
    "        phase_log_losses = []\n",
    "        phase_confidences = []\n",
    "        phase_accuracies = []\n",
    "\n",
    "        for sample in phase_data[phase]:\n",
    "            preds = sample['preds']\n",
    "            targets = sample['targets']\n",
    "\n",
    "            if len(preds) < 2:\n",
    "                continue\n",
    "\n",
    "            # Winner prediction\n",
    "            pred_winner = np.argmax(preds)\n",
    "            target_winner = np.argmax(targets)\n",
    "\n",
    "            is_correct = pred_winner == target_winner\n",
    "            if is_correct:\n",
    "                phase_correct += 1\n",
    "            phase_total += 1\n",
    "\n",
    "            # Softmax for probabilities\n",
    "            probs = softmax(preds)\n",
    "            winner_prob = probs[target_winner]\n",
    "\n",
    "            # Log loss\n",
    "            winner_prob_clipped = np.clip(winner_prob, 1e-7, 1 - 1e-7)\n",
    "            phase_log_losses.append(-np.log(winner_prob_clipped))\n",
    "\n",
    "            # For ECE\n",
    "            confidence = np.max(probs)\n",
    "            phase_confidences.append(confidence)\n",
    "            phase_accuracies.append(float(is_correct))\n",
    "\n",
    "        # Phase accuracy\n",
    "        if phase_total > 0:\n",
    "            results['accuracy'][f'Phase_{phase}'] = phase_correct / phase_total\n",
    "        else:\n",
    "            results['accuracy'][f'Phase_{phase}'] = 0.0\n",
    "\n",
    "        # Phase log loss\n",
    "        if phase_log_losses:\n",
    "            results['log_loss'][f'Phase_{phase}'] = np.mean(phase_log_losses)\n",
    "        else:\n",
    "            results['log_loss'][f'Phase_{phase}'] = 0.0\n",
    "\n",
    "        # Phase ECE\n",
    "        if phase_confidences:\n",
    "            results['ece'][f'Phase_{phase}'] = compute_ece(\n",
    "                np.array(phase_confidences),\n",
    "                np.array(phase_accuracies),\n",
    "            )\n",
    "        else:\n",
    "            results['ece'][f'Phase_{phase}'] = 0.0\n",
    "\n",
    "        # Accumulate for average\n",
    "        all_correct += phase_correct\n",
    "        all_total += phase_total\n",
    "        all_log_losses.extend(phase_log_losses)\n",
    "        all_confidences.extend(phase_confidences)\n",
    "        all_accuracies.extend(phase_accuracies)\n",
    "\n",
    "    # Average metrics\n",
    "    if all_total > 0:\n",
    "        results['accuracy']['Average'] = all_correct / all_total\n",
    "    else:\n",
    "        results['accuracy']['Average'] = 0.0\n",
    "\n",
    "    if all_log_losses:\n",
    "        results['log_loss']['Average'] = np.mean(all_log_losses)\n",
    "    else:\n",
    "        results['log_loss']['Average'] = 0.0\n",
    "\n",
    "    if all_confidences:\n",
    "        results['ece']['Average'] = compute_ece(\n",
    "            np.array(all_confidences),\n",
    "            np.array(all_accuracies),\n",
    "        )\n",
    "    else:\n",
    "        results['ece']['Average'] = 0.0\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21910772-1fc1-4e54-9548-0120eb2b90ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63d00ec1-973f-455f-98e5-c624f160b120",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60314b4d-2d7d-43cc-a7e6-7c60919e1060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6bf71cc-8260-4879-b74a-21cb52d36d90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def print_results(results, title=\"Results\"):\n",
    "    \"\"\"Print results in a formatted table.\"\"\"\n",
    "    print()\n",
    "    print(\"=\" * 90)\n",
    "    print(title)\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    metrics = ['accuracy', 'log_loss', 'ece']\n",
    "    phases = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "\n",
    "    # Header\n",
    "    header = f\"{'Phase':<12}\"\n",
    "    for metric in metrics:\n",
    "        header += f\"{metric.upper():<15}\"\n",
    "    print(header)\n",
    "    print(\"-\" * 90)\n",
    "\n",
    "    # Phase rows\n",
    "    for phase in phases:\n",
    "        row = f\"{phase:<12}\"\n",
    "        for metric in metrics:\n",
    "            val = results[metric].get(phase, 0.0)\n",
    "            row += f\"{val:<15.4f}\"\n",
    "        print(row)\n",
    "\n",
    "    # Average row\n",
    "    print(\"-\" * 90)\n",
    "    avg_row = f\"{'Average':<12}\"\n",
    "    for metric in metrics:\n",
    "        val = results[metric].get('Average', 0.0)\n",
    "        avg_row += f\"{val:<15.4f}\"\n",
    "    print(avg_row)\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Computing phase-wise metrics...\")\n",
    "test_df['dist_from_bluezone'] = test_df['dist_from_bluezone'].replace(-1, 999)\n",
    "test_df['dist_from_whitezone'] = test_df['dist_from_whitezone'].replace(-1, 999)\n",
    "\n",
    "for c in ['dist_from_bluezone','dist_from_bluezone_v2']:\n",
    "    test_df['pred'] = -test_df[c]\n",
    "    results = compute_metrics_by_phase(test_df)\n",
    "    print_results(results, title=f\"Rule-Based Baseline: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4cee748-e498-4a16-81c7-49297597e54f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for c in ['dist_from_whitezone','dist_from_whitezone_v2']:\n",
    "    test_df['pred'] = -test_df[c]\n",
    "    results = compute_metrics_by_phase(test_df)\n",
    "    print_results(results, title=f\"Rule-Based Baseline: {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8e26e35-ec99-46ee-a658-09afa26dc9d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.index.name = 'Metric'\n",
    "results_df = results_df.T\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "634e7a64-6714-4134-bdcb-893750e84b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "667f2a97-74d1-4be0-a963-a7c8b7a6106d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "OUTPUT_DIR = \"/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/pgc_results/rule_based\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save as CSV (same format as other experiments)\n",
    "summary_data = []\n",
    "for metric in ['accuracy', 'log_loss', 'ece']:\n",
    "    row = {'metric': metric}\n",
    "    row.update(results[metric])\n",
    "    summary_data.append(row)\n",
    "\n",
    "save_df = pd.DataFrame(summary_data)\n",
    "save_path = os.path.join(OUTPUT_DIR, \"test_results.csv\")\n",
    "save_df.to_csv(save_path, index=False)\n",
    "print(f\"Results saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37a8fcfb-8865-42c3-af9f-16abe5169771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "481ae351-4448-4a01-a20b-eb260286a6b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot phase-wise accuracy\n",
    "phases = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "accuracies = [results['accuracy'][p] for p in phases]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(range(1, NUM_PHASES + 1), accuracies, color='steelblue', alpha=0.8)\n",
    "ax.axhline(y=results['accuracy']['Average'], color='red', linestyle='--', label=f\"Average: {results['accuracy']['Average']:.4f}\")\n",
    "ax.set_xlabel('Phase', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Rule-Based Baseline: Phase-wise Accuracy\\n(Lower dist_from_bluezone = Winner)', fontsize=14)\n",
    "ax.set_xticks(range(1, NUM_PHASES + 1))\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "rule_based_baseline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
