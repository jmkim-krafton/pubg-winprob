{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e445940-a2bc-4911-8e9e-16771bed193e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model Comparison: Phase-wise Test Results\n",
    "\n",
    "Compare test results across different model configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aeaea30-a875-4dd0-b575-a34c896f8c39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "858b4379-bd3d-466a-a05b-72c85fe57106",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.listdir('/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/pgc_results/inference_v2_1sec_viz/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "049260db-ed21-4fb4-b476-91e801128711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECKPOINT_DIR = \"/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/pgc_results/checkpoints\"\n",
    "NUM_PHASES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef7ffdc2-a9ca-4d05-80b0-41240bf21dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lgbm = pd.read_csv('/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/pgc_results/lgbm/leaves31_lr0.1/test_results.csv').loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "589c65f8-c3cd-46c1-9724-d0df30edf914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Load All Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48cf91eb-8cd7-4c71-b15b-a22d68f18346",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_all_results(checkpoint_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load test_results.csv from all experiment folders.  \n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: model_name, metric, Phase_1, ..., Phase_10, Average\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Find all experiment directories\n",
    "    exp_dirs = sorted(glob.glob(os.path.join(checkpoint_dir, \"*\")))\n",
    "    exp_dirs = [x for x in exp_dirs if 'toy' not in x]\n",
    "    \n",
    "    for exp_dir in exp_dirs:\n",
    "        if not os.path.isdir(exp_dir):\n",
    "            continue\n",
    "            \n",
    "        results_path = os.path.join(exp_dir, \"test_results.csv\")\n",
    "        config_path = os.path.join(exp_dir, \"config.json\")\n",
    "        \n",
    "        if not os.path.exists(results_path):\n",
    "            continue\n",
    "            \n",
    "        # Load results\n",
    "        df = pd.read_csv(results_path)\n",
    "        \n",
    "        # Get model name from directory\n",
    "        model_name = os.path.basename(exp_dir)\n",
    "        \n",
    "        # Try to load config for more details\n",
    "        config = {}\n",
    "        if os.path.exists(config_path):\n",
    "            with open(config_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "        \n",
    "        # Add model info\n",
    "        df['model_name'] = model_name\n",
    "        df['embed_dim'] = config.get('embed_dim', 'N/A')\n",
    "        df['num_heads'] = config.get('num_heads', 'N/A')\n",
    "        df['num_layers'] = config.get('num_layers', 'N/A')\n",
    "        df['loss_type'] = config.get('loss_type', 'mse')\n",
    "        df['lr'] = config.get('lr', 'N/A')\n",
    "        \n",
    "        all_results.append(df)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"No results found!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Load results\n",
    "results_df = load_all_results(CHECKPOINT_DIR)\n",
    "print(f\"Loaded {len(results_df)} rows from {results_df['model_name'].nunique()} models\")\n",
    "results_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c244e122-10cf-4b47-9b29-d59dd090fa50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Accuracy Summary Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e108ba-0912-481a-9cde-b5f52784415e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter accuracy rows\n",
    "accuracy_df = results_df[results_df['metric'] == 'accuracy'].copy()\n",
    "\n",
    "# Phase columns\n",
    "phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "display_cols = ['model_name', 'embed_dim', 'num_heads', 'num_layers', 'loss_type'] + phase_cols + ['Average']\n",
    "\n",
    "# Sort by Average accuracy\n",
    "accuracy_df = accuracy_df.sort_values('Average', ascending=False)\n",
    "accuracy_df = accuracy_df[accuracy_df['loss_type'] == 'mse']\n",
    "accuracy_df[phase_cols] = accuracy_df[phase_cols]*100\n",
    "accuracy_df['Average'] = accuracy_df['Average']*100\n",
    "mse = accuracy_df.iloc[0]\n",
    "print(\"Accuracy Results (sorted by Average):\")\n",
    "accuracy_df[display_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91937132-e722-4047-867f-d2a77a8d7568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter accuracy rows\n",
    "accuracy_df = results_df[results_df['metric'] == 'accuracy'].copy()\n",
    "\n",
    "# Phase columns\n",
    "phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "display_cols = ['model_name', 'embed_dim', 'num_heads', 'num_layers', 'loss_type'] + phase_cols + ['Average']\n",
    "\n",
    "# Sort by Average accuracy\n",
    "accuracy_df = accuracy_df.sort_values('Average', ascending=False)\n",
    "accuracy_df = accuracy_df[accuracy_df['loss_type'] == 'cox']\n",
    "accuracy_df[phase_cols] = accuracy_df[phase_cols]*100\n",
    "accuracy_df['Average'] = accuracy_df['Average']*100\n",
    "cox = accuracy_df.iloc[0]\n",
    "print(\"Accuracy Results (sorted by Average):\")\n",
    "accuracy_df[display_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a548b25-c105-4331-8330-7e725e246738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter accuracy rows\n",
    "accuracy_df = results_df[results_df['metric'] == 'accuracy'].copy()\n",
    "\n",
    "# Phase columns\n",
    "phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "display_cols = ['model_name', 'embed_dim', 'num_heads', 'num_layers', 'loss_type'] + phase_cols + ['Average']\n",
    "\n",
    "# Sort by Average accuracy\n",
    "accuracy_df = accuracy_df.sort_values('Average', ascending=False)\n",
    "accuracy_df = accuracy_df[accuracy_df['loss_type'] == 'rank_cox']\n",
    "accuracy_df[phase_cols] = accuracy_df[phase_cols]*100\n",
    "accuracy_df['Average'] = accuracy_df['Average']*100\n",
    "rank_cox = accuracy_df.iloc[0]\n",
    "print(\"Accuracy Results (sorted by Average):\")\n",
    "accuracy_df[display_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27381eea-0078-4b9c-a16a-7cb7d985e32d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter accuracy rows\n",
    "accuracy_df = results_df[results_df['metric'] == 'accuracy'].copy()\n",
    "\n",
    "# Phase columns\n",
    "phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "display_cols = ['model_name', 'embed_dim', 'num_heads', 'num_layers', 'loss_type'] + phase_cols + ['Average']\n",
    "\n",
    "# Sort by Average accuracy\n",
    "accuracy_df = accuracy_df.sort_values('Average', ascending=False)\n",
    "accuracy_df = accuracy_df[(accuracy_df['loss_type'] == 'weighted_cox') & (accuracy_df['model_name'].str.contains('v11'))]\n",
    "accuracy_df[phase_cols] = accuracy_df[phase_cols]*100\n",
    "accuracy_df['Average'] = accuracy_df['Average']*100\n",
    "weighted_cox = accuracy_df.iloc[0]\n",
    "print(\"Accuracy Results (sorted by Average):\")\n",
    "accuracy_df[display_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b78d45e-8183-442a-850c-f83ab8698f43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.iloc[0]['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0408fa9-08d6-4fa6-b137-8c17ad58fede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter accuracy rows\n",
    "accuracy_df = results_df[results_df['metric'] == 'accuracy'].copy()\n",
    "\n",
    "# Phase columns\n",
    "phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "display_cols = ['model_name', 'embed_dim', 'num_heads', 'num_layers', 'loss_type'] + phase_cols + ['Average']\n",
    "\n",
    "# Sort by Average accuracy\n",
    "accuracy_df = accuracy_df.sort_values('Average', ascending=False)\n",
    "accuracy_df = accuracy_df[accuracy_df['loss_type'] == 'concordance']\n",
    "accuracy_df[phase_cols] = accuracy_df[phase_cols]*100\n",
    "accuracy_df['Average'] = accuracy_df['Average']*100\n",
    "concordance = accuracy_df.iloc[0]\n",
    "print(\"Accuracy Results (sorted by Average):\")\n",
    "accuracy_df[display_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62e6dd0b-ff1e-4d17-a0f8-a3fb37d206e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter accuracy rows\n",
    "accuracy_df = results_df[results_df['metric'] == 'accuracy'].copy()\n",
    "\n",
    "# Phase columns\n",
    "phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "display_cols = ['model_name', 'embed_dim', 'num_heads', 'num_layers', 'loss_type'] + phase_cols + ['Average']\n",
    "\n",
    "# Sort by Average accuracy\n",
    "accuracy_df = accuracy_df.sort_values('Average', ascending=False)\n",
    "accuracy_df = accuracy_df[accuracy_df['loss_type'] == 'survival_ce']\n",
    "accuracy_df[phase_cols] = accuracy_df[phase_cols]*100\n",
    "accuracy_df['Average'] = accuracy_df['Average']*100\n",
    "survival_ce = accuracy_df.iloc[0]\n",
    "print(\"Accuracy Results (sorted by Average):\")\n",
    "accuracy_df[display_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47118194-8748-4b75-8403-715ef1f38ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = pd.concat([mse,cox,rank_cox,weighted_cox, survival_ce],axis=1).T\n",
    "results = results.iloc[:,1:12]\n",
    "tmp = pd.DataFrame(lgbm.values[1:]).T\n",
    "tmp = tmp*100\n",
    "tmp.columns = results.columns\n",
    "results = pd.concat([results,tmp],axis=0)\n",
    "results.index = ['Ours-mse','Ours-fullall', 'Ours-rank_cox','Ours-weighted_cox','Ours-CE', 'LGBM']\n",
    "results = results.astype('float')\n",
    "results = results.sort_values('Average', ascending=False)\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "407b0584-0399-4355-acf0-c1e759a69a83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Phase labels\n",
    "phases = [\"Phase_1\", \"Phase_2\", \"Phase_3\", \"Phase_4\", \"Phase_5\",\n",
    "          \"Phase_6\", \"Phase_7\", \"Phase_8\", \"Phase_9\", \"Phase_10\"]\n",
    "\n",
    "# Data\n",
    "ours_mse = [10.29, 15.22, 22.18, 28.96, 38.99, 53.01, 68.09, 80.54, 94.19, 100.00]\n",
    "ours_rank_cox = [10.20, 16.18, 21.38, 28.96, 37.42, 51.96, 67.20, 81.03, 94.23, 100.00]\n",
    "ours_weighted_cox = [8.46, 14.21, 18.10, 25.86, 36.74, 49.45, 67.01, 80.61, 94.00, 99.77]\n",
    "lgbm = [10.29, 15.78, 21.92, 25.21, 31.32, 44.03, 59.58, 74.72, 91.35, 99.70]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(phases, ours_mse, marker=\"o\", label=\"Ours-mse\")\n",
    "plt.plot(phases, ours_rank_cox, marker=\"o\", label=\"Ours-rank_cox\")\n",
    "plt.plot(phases, ours_weighted_cox, marker=\"o\", label=\"Ours-weighted_cox\")\n",
    "plt.plot(phases, lgbm, marker=\"o\", label=\"LGBM\")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Phase\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance by Phase\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d64b424-15d5-4bce-8955-0a92c585484c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results.index = ['Ours-mse','Ours-rank_cox','Ours-weighted_cox','LGBM']\n",
    "results = results.astype('float')\n",
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52a2d030-3f48-4c79-9fd4-8b7195447beb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lgbm.values[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d518fed-59a9-485e-9513-d9f34c1b5698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Phase-wise Accuracy Trends (Line Plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b148cd9-a631-4737-a07b-b11d0d2dd293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_phase_trends(df: pd.DataFrame, metric: str = 'accuracy', top_n: int = 5):\n",
    "    \"\"\"Plot phase trends as line plot.\"\"\"\n",
    "    metric_df = df[df['metric'] == metric].copy()\n",
    "    metric_df = metric_df.sort_values('Average', ascending=False).head(top_n)\n",
    "    \n",
    "    phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for _, row in metric_df.iterrows():\n",
    "        values = [row[col] for col in phase_cols]\n",
    "        label = row['model_name'][:40] if len(row['model_name']) > 40 else row['model_name']\n",
    "        ax.plot(range(1, NUM_PHASES + 1), values, marker='o', linewidth=2, markersize=6, label=label)\n",
    "    \n",
    "    ax.set_xlabel('Phase', fontsize=12)\n",
    "    ax.set_ylabel(metric.upper(), fontsize=12)\n",
    "    ax.set_title(f'Phase-wise {metric.upper()} Trends (Top {top_n} Models)', fontsize=14)\n",
    "    ax.set_xticks(range(1, NUM_PHASES + 1))\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy trends\n",
    "if len(results_df) > 0:\n",
    "    plot_phase_trends(results_df, metric='accuracy', top_n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "783f9b68-a6c9-4be8-bfb4-fa18dce4139b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Heatmap: Phase-wise Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a608f261-9d79-425d-a0d3-ccbb1c666d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_heatmap(df: pd.DataFrame, top_n: int = 10):\n",
    "    \"\"\"Plot heatmap of phase-wise accuracy.\"\"\"\n",
    "    accuracy_df = df[df['metric'] == 'accuracy'].copy()\n",
    "    accuracy_df = accuracy_df.sort_values('Average', ascending=False).head(top_n)\n",
    "    \n",
    "    phase_cols = [f'Phase_{i}' for i in range(1, NUM_PHASES + 1)] + ['Average']\n",
    "    \n",
    "    # Create matrix\n",
    "    heatmap_data = accuracy_df.set_index('model_name')[phase_cols]\n",
    "    \n",
    "    # Shorten model names for display\n",
    "    heatmap_data.index = [name[:35] + '...' if len(name) > 35 else name for name in heatmap_data.index]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, max(6, len(heatmap_data) * 0.5)))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        fmt='.3f',\n",
    "        cmap='RdYlGn',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Accuracy'}\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Phase-wise Accuracy Heatmap', fontsize=14)\n",
    "    ax.set_xlabel('Phase', fontsize=12)\n",
    "    ax.set_ylabel('Model', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot heatmap\n",
    "if len(results_df) > 0:\n",
    "    plot_accuracy_heatmap(results_df, top_n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b45f771a-86d4-4106-83eb-3c5a26a81ba5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. All Metrics Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a21123fc-5ca7-46e9-93e9-fee2c4afad79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create summary table with all metrics for each model.\"\"\"\n",
    "    metrics = ['accuracy', 'log_loss', 'ece']\n",
    "    summary_data = []\n",
    "    \n",
    "    for model_name in df['model_name'].unique():\n",
    "        model_df = df[df['model_name'] == model_name]\n",
    "        \n",
    "        row = {'model_name': model_name}\n",
    "        \n",
    "        # Get config info from first row\n",
    "        first_row = model_df.iloc[0]\n",
    "        row['embed_dim'] = first_row.get('embed_dim', 'N/A')\n",
    "        row['num_heads'] = first_row.get('num_heads', 'N/A')\n",
    "        row['num_layers'] = first_row.get('num_layers', 'N/A')\n",
    "        row['loss_type'] = first_row.get('loss_type', 'mse')\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric_row = model_df[model_df['metric'] == metric]\n",
    "            if len(metric_row) > 0:\n",
    "                row[f'{metric}_avg'] = metric_row['Average'].values[0]\n",
    "            else:\n",
    "                row[f'{metric}_avg'] = np.nan\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('accuracy_avg', ascending=False)\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Create and display summary\n",
    "summary_df = create_summary_table(results_df)\n",
    "print(\"Model Summary (sorted by Average Accuracy):\")\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6914a2bb-6c08-4b11-9d7f-b8439c640d1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Best Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c759d51-a7d9-4e6a-bbd7-92cc50fb9b8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find best model\n",
    "if len(summary_df) > 0:\n",
    "    best_model = summary_df.iloc[0]\n",
    "    print(\"Best Model:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Name: {best_model['model_name']}\")\n",
    "    print(f\"Embed Dim: {best_model['embed_dim']}\")\n",
    "    print(f\"Num Heads: {best_model['num_heads']}\")\n",
    "    print(f\"Num Layers: {best_model['num_layers']}\")\n",
    "    print(f\"Loss Type: {best_model['loss_type']}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Average Accuracy: {best_model['accuracy_avg']:.4f}\")\n",
    "    print(f\"Average Log Loss: {best_model['log_loss_avg']:.4f}\")\n",
    "    print(f\"Average ECE: {best_model['ece_avg']:.4f}\")\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7057f87c-63ed-46e7-b6c5-dea84e61b8cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Export Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9f6a122-1e2a-499b-8a5e-743e80130907",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save summary to CSV\n",
    "output_path = os.path.join(CHECKPOINT_DIR, \"model_comparison_summary.csv\")\n",
    "summary_df.to_csv(output_path, index=False)\n",
    "print(f\"Summary saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "compare_results",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
