"""
High RP Matches CSV ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
matchidì—ì„œ year, month, day, hourë¥¼ ì¶”ì¶œí•˜ì—¬ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
"""

import pandas as pd
import os

def extract_datetime_from_matchid(matchid):
    """
    matchidì—ì„œ year, month, day, hour ì •ë³´ ì¶”ì¶œ
    
    matchid ì˜ˆì‹œ: match.bro.competitive.pc-2018-37.steam.squad.as.2025.10.01.19.00811236-0c6f-4d9c-b720-94e649366267
    í† í° êµ¬ì¡°: match.bro.{league_type}.{season}.{platform}.{mode}.{region}.{year}.{month}.{day}.{hour}.{uuid}
    """
    try:
        tokens = matchid.split('.')
        year = tokens[7]
        month = tokens[8]
        day = tokens[9]
        hour = tokens[10]
        
        return year, month, day, hour
    except Exception as e:
        print(f"Error parsing matchid: {matchid}, Error: {e}")
        return None, None, None, None

def preprocess_high_rp_matches(input_csv_path, output_csv_path=None):
    """
    High RP matches CSV íŒŒì¼ì„ ì½ì–´ year, month, day, hour ì»¬ëŸ¼ ì¶”ê°€
    
    Args:
        input_csv_path: ì›ë³¸ CSV íŒŒì¼ ê²½ë¡œ
        output_csv_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ _with_datetime.csv ì ‘ë¯¸ì‚¬ ì¶”ê°€)
    
    Returns:
        ì²˜ë¦¬ëœ DataFrame
    """
    print(f"ğŸ“– Reading CSV file: {input_csv_path}")
    
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(input_csv_path)
    
    print(f"âœ… Loaded {len(df)} rows")
    print(f"ğŸ“Š Columns: {list(df.columns)}")
    
    # matchid ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
    if 'matchid' not in df.columns:
        raise ValueError("CSV file must contain 'matchid' column")
    
    # year, month, day, hour ì¶”ì¶œ
    print(f"ğŸ”„ Extracting datetime information from matchid...")
    datetime_info = df['matchid'].apply(extract_datetime_from_matchid)
    
    # ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€
    df['year'] = datetime_info.apply(lambda x: x[0])
    df['month'] = datetime_info.apply(lambda x: x[1])
    df['day'] = datetime_info.apply(lambda x: x[2])
    df['hour'] = datetime_info.apply(lambda x: x[3])
    
    # íŒŒì‹± ì‹¤íŒ¨í•œ í–‰ í™•ì¸
    failed_rows = df[df['year'].isna()]
    if len(failed_rows) > 0:
        print(f"âš ï¸  Warning: {len(failed_rows)} rows failed to parse")
        print(f"   Example failed matchid: {failed_rows.iloc[0]['matchid']}")
    
    # íŒŒì‹± ì„±ê³µí•œ í–‰ë§Œ ìœ ì§€
    df_clean = df.dropna(subset=['year', 'month', 'day', 'hour'])
    
    print(f"âœ… Successfully parsed {len(df_clean)} rows")
    print(f"ğŸ“Š Date range:")
    print(f"   - Years: {sorted(df_clean['year'].unique())}")
    print(f"   - Months: {sorted(df_clean['month'].unique())}")
    
    # ë‚ ì§œ/ì‹œê°„ë³„ í†µê³„
    date_hour_counts = df_clean.groupby(['year', 'month', 'day', 'hour']).size().reset_index(name='count')
    print(f"\nğŸ“ˆ Statistics:")
    print(f"   - Total unique date-hour combinations: {len(date_hour_counts)}")
    print(f"   - Total matches: {len(df_clean)}")
    print(f"   - Average matches per date-hour: {len(df_clean) / len(date_hour_counts):.2f}")
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ê²°ì •
    if output_csv_path is None:
        base_name = os.path.splitext(input_csv_path)[0]
        output_csv_path = f"{base_name}_with_datetime.csv"
    
    # CSV ì €ì¥
    print(f"\nğŸ’¾ Saving to: {output_csv_path}")
    df_clean.to_csv(output_csv_path, index=False)
    print(f"âœ… Saved successfully!")
    
    return df_clean

def create_matchid_lookup_dict(df):
    """
    ë‚ ì§œ/ì‹œê°„ë³„ë¡œ matchidë¥¼ ê·¸ë£¹í™”í•œ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¡°íšŒë¥¼ ìœ„í•œ ìë£Œêµ¬ì¡°
    
    Args:
        df: year, month, day, hour, matchid ì»¬ëŸ¼ì„ í¬í•¨í•œ DataFrame
    
    Returns:
        {(year, month, day, hour): set(matchid1, matchid2, ...)}
    """
    print(f"\nğŸ”¨ Creating matchid lookup dictionary...")
    
    lookup_dict = {}
    
    for _, row in df.iterrows():
        key = (row['year'], row['month'], row['day'], row['hour'])
        if key not in lookup_dict:
            lookup_dict[key] = set()
        lookup_dict[key].add(row['matchid'])
    
    print(f"âœ… Created lookup dictionary:")
    print(f"   - Unique date-hour keys: {len(lookup_dict)}")
    print(f"   - Total matches: {sum(len(v) for v in lookup_dict.values())}")
    
    return lookup_dict

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì • (Databricks í™˜ê²½ ê¸°ì¤€)
    BASE_PATH = "/Volumes/main_dev/dld_ml_anticheat_test/anticheat_test_volume/pgc_wwcd/competitive_high_rp_match/"
    INPUT_CSV = f"{BASE_PATH}/high_rp_matches_as_squad_fpp_20250525_20251125.csv"
    OUTPUT_CSV = f"{BASE_PATH}/high_rp_matches_as_squad_fpp_20250525_20251125_with_datetime.csv"
    
    print("="*60)
    print("High RP Matches CSV ì „ì²˜ë¦¬")
    print("="*60)
    
    # CSV ì „ì²˜ë¦¬
    df = preprocess_high_rp_matches(INPUT_CSV, OUTPUT_CSV)
    
    # Lookup ë”•ì…”ë„ˆë¦¬ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    lookup_dict = create_matchid_lookup_dict(df)
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"\nğŸ“‹ Sample lookup entries:")
    for i, (key, matchids) in enumerate(list(lookup_dict.items())[:3]):
        print(f"   {key}: {len(matchids)} matches")
        if i == 0:
            print(f"      Example matchid: {list(matchids)[0]}")
    
    print("\nâœ… Preprocessing complete!")
    print(f"ğŸ“ Output file: {OUTPUT_CSV}")

if __name__ == "__main__":
    main()
